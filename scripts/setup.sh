#!/bin/bash

# Multimodal RAG System Setup Script
# This script helps set up the complete system

set -e

echo "ğŸš€ Multimodal RAG System Setup"
echo "==============================="

# Check if running on macOS
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "âœ… Running on macOS"
else
    echo "âš ï¸  This script is optimized for macOS. Please adapt for your system."
fi

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Check system requirements
echo "ğŸ” Checking system requirements..."

# Check Docker
if command_exists docker; then
    echo "âœ… Docker is installed"
    docker --version
else
    echo "âŒ Docker not found. Please install Docker Desktop"
    exit 1
fi

# Check Docker Compose
if command_exists docker-compose; then
    echo "âœ… Docker Compose is installed"
    docker-compose --version
else
    echo "âŒ Docker Compose not found. Please install Docker Compose"
    exit 1
fi

# Check Ollama
if command_exists ollama; then
    echo "âœ… Ollama is installed"
    ollama --version
else
    echo "ğŸ“¦ Installing Ollama..."
    if [[ "$OSTYPE" == "darwin"* ]]; then
        if command_exists brew; then
            brew install ollama
        else
            echo "âŒ Homebrew not found. Please install Ollama manually from https://ollama.ai"
            exit 1
        fi
    else
        echo "âŒ Please install Ollama manually from https://ollama.ai"
        exit 1
    fi
fi

# Check Python (for development)
if command_exists python3; then
    echo "âœ… Python 3 is installed"
    python3 --version
else
    echo "âš ï¸  Python 3 not found. Install for development purposes."
fi

# Check Node.js (for frontend development)
if command_exists node; then
    echo "âœ… Node.js is installed"
    node --version
else
    echo "âš ï¸  Node.js not found. Install for frontend development."
fi

echo ""
echo "ğŸ› ï¸  Setting up environment..."

# Create environment file
if [ ! -f .env ]; then
    echo "ğŸ“ Creating .env file..."
    cat > .env << EOL
# Multimodal RAG System Environment Configuration

# Application Settings
DEBUG=false
HOST=0.0.0.0
PORT=8000

# Database Configuration
DATABASE_URL=postgresql://postgres:password@localhost:5432/multimodal_rag

# Vector Database Configuration
VECTOR_DB_PATH=./data/vector_db
VECTOR_DB_TYPE=chromadb
EMBEDDING_DIM=384

# Embedding Model Configuration
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_TIMEOUT=120

# File Upload Configuration
MAX_FILE_SIZE=52428800
ALLOWED_EXTENSIONS=.pdf
UPLOAD_DIRECTORY=./data/uploads

# Processing Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_CHUNKS_PER_QUERY=5

# Retrieval Configuration
RETRIEVAL_K=10
RERANK_K=5
SIMILARITY_THRESHOLD=0.7

# Scoring Weights
SEMANTIC_WEIGHT=0.6
LEXICAL_WEIGHT=0.3
TABLE_BOOST=1.2

# Security Configuration
SECRET_KEY=your-secret-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Logging Configuration
LOG_LEVEL=INFO

# Evaluation Configuration
EVALUATION_DATASET_PATH=./data/evaluation/test_queries.json
TARGET_ACCURACY=0.98
EOL
    echo "âœ… Environment file created"
else
    echo "âœ… Environment file already exists"
fi

# Create data directories
echo "ğŸ“ Creating data directories..."
mkdir -p data/uploads
mkdir -p data/vector_db
mkdir -p data/evaluation
mkdir -p logs

echo "âœ… Data directories created"

# Start Ollama service
echo "ğŸ¦™ Starting Ollama service..."
if pgrep -f "ollama serve" > /dev/null; then
    echo "âœ… Ollama service is already running"
else
    echo "ğŸš€ Starting Ollama service in background..."
    ollama serve &
    sleep 3
fi

# Download recommended models
echo "ğŸ“¥ Downloading recommended models..."
echo "This may take a while depending on your internet connection..."

# Download LLM model
if ollama list | grep -q "llama2"; then
    echo "âœ… llama2 model already downloaded"
else
    echo "ğŸ“¥ Downloading llama2 model..."
    ollama pull llama2
fi

# Optional: Download a smaller model for testing
if ollama list | grep -q "phi"; then
    echo "âœ… phi model already downloaded"
else
    echo "ğŸ“¥ Downloading phi model (smaller, for testing)..."
    ollama pull phi
fi

echo ""
echo "ğŸ³ Setting up Docker containers..."

# Build and start containers
echo "ğŸ”¨ Building Docker images..."
docker-compose build

echo "ğŸš€ Starting services..."
docker-compose up -d

# Wait for services to be ready
echo "â³ Waiting for services to be ready..."
sleep 10

# Check service health
echo "ğŸ¥ Checking service health..."
for i in {1..30}; do
    if curl -s http://localhost:8000/api/health > /dev/null; then
        echo "âœ… Backend service is healthy"
        break
    else
        echo "â³ Waiting for backend service... (attempt $i/30)"
        sleep 2
    fi
done

# Test basic functionality
echo "ğŸ§ª Testing basic functionality..."
if curl -s -X POST "http://localhost:8000/api/query" \
   -H "Content-Type: application/json" \
   -H "Authorization: Bearer demo-token" \
   -d '{"query": "test"}' > /dev/null; then
    echo "âœ… API is responding"
else
    echo "âš ï¸  API test failed - check logs with: docker-compose logs backend"
fi

echo ""
echo "ğŸ‰ Setup Complete!"
echo "=================="
echo ""
echo "ğŸŒ Access Points:"
echo "  â€¢ Frontend:     http://localhost:3000"
echo "  â€¢ API Docs:     http://localhost:8000/api/docs"
echo "  â€¢ Monitoring:   http://localhost:3001 (admin/admin)"
echo ""
echo "ğŸ”‘ Authentication:"
echo "  â€¢ Demo Token:   demo-token"
echo ""
echo "ğŸ“‹ Next Steps:"
echo "  1. Open http://localhost:3000 in your browser"
echo "  2. Upload a PDF document"
echo "  3. Ask questions about your documents"
echo ""
echo "ğŸ› ï¸  Development:"
echo "  â€¢ View logs:    docker-compose logs -f"
echo "  â€¢ Stop system:  docker-compose down"
echo "  â€¢ Restart:      docker-compose restart"
echo ""
echo "ğŸ“– Documentation:"
echo "  â€¢ README.md for detailed information"
echo "  â€¢ API docs at http://localhost:8000/api/docs"
echo ""
echo "Happy querying! ğŸ¯" 